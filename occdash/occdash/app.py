import logging
import os
from pathlib import Path

import dash
import dash_core_components as dcc
import dash_html_components as html
import networkx
import networkx as nx
from dash.dependencies import Input, Output
import json
from flask_caching import Cache


import occdash
import pyspike
import pyspike.temporal
import occ.vis.analysis
import pyspike.network_dash
from pyspike import tidydata, temporal
from pyspike.sacred.sacredrun import SacredRun

RUN_180 = SacredRun(Path(occdash.__file__).parent.parent / 'tests' / 'files' / 'run_180')
logging.basicConfig(level=logging.DEBUG)




def load_medium_graph(medium_gml_path: Path):
    return nx.read_gml(str(medium_gml_path), destringizer=int)


RUN_PATH_BASE = Path('/Users/walton/Documents/DPhil/proof-of-concept/runs')


MEDIUM_GRAPH = load_medium_graph(RUN_180.medium_graph_path)



external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']

styles = {
    'pre': {
        'border': 'thin lightgrey solid',
        'overflowX': 'scroll'
    }
}


app = dash.Dash(__name__, external_stylesheets=external_stylesheets)

CACHE_CONFIG = {
    # try 'filesystem' if you don't want to setup redis
    # 'CACHE_TYPE': 'filesystem',
    # 'CACHE_DIR': '/Users/walton/Documents/DPhil/proof-of-concept/flask_cache',
    'CACHE_TYPE': 'redis',
    'CACHE_REDIS_URL': os.environ.get('REDIS_URL', 'localhost:6379')
}
cache = Cache()
cache.init_app(app.server, config=CACHE_CONFIG)


# We are assigning callbacks to components that are generated by other callbacks
# This requires:
app.config['suppress_callback_exceptions'] = True


app.layout = html.Div([

    dcc.Location(id='url', refresh=False),

    dcc.Store(id='run-id'),  # store run number: integer or None

    html.Div(id='url-error'),  # Leave empty unless error to display

    html.Div(
        dcc.Graph(
            id='occasion-graph-graph',
            # TODO: remove
            # figure=pyspike.temporal.generate_causal_graph_figure(build_occasion_graph(RUN_180.places_path, RUN_180.transitions_path), MEDIUM_GRAPH, run_id=None),
            style={'width': '800', 'height': '800'}
        ),
        style={'display': 'inline-block'}
    ),
    html.Div([
        dcc.Graph(
            id='place-count-graph',
            style={'width': '400'},
        ),
        dcc.Graph(
            id='network-graph',
            style={'width': '400'}
        ),
        html.Div(id='network-graph-slider-keeper')
        ],
        style={'display': 'inline-block'}
    ),

    html.Div(
        id='run-info',
    ),

    dcc.Markdown('''

#### Todo

- Check all old features working
- Add cache
- Create a table showing run info
- Make the big grap take 800 wide and stack other 2


#### Feature ideas

- Create a link that zooms into the big graph
- Allow selection of nodes in the network graph to filer those shown in causal graph
- Animate movie button
- Export state at time button
- DIAMOND - show that multiple open windows may interact.

#### Done

****

#### Simulation side
[ ] Use exported state


#### Tips


Dash supports [Markdown](http://commonmark.org/help).

Markdown is a simple way to write and format text.
It includes a syntax for things like **bold text** and *italics*,
[links](http://commonmark.org/help), inline `code` snippets, lists,
quotes, and more.
    '''),

])


@app.callback(Output('run-id', 'data'), [Input('url', 'pathname')])
def update_run_id(pathname):
    try:
        run_id = run_id_from_url(pathname)  # throws ValueError
    except ValueError:
        run_id = None
    logging.info(f'Updating run-id to {run_id}')
    return run_id


@app.callback(Output('url-error', 'children'), [Input('url', 'pathname')])
def update_url_error(pathname):
    try:
        run_id_from_url(pathname)
    except ValueError as e:
        logging.error(e.args[0])
        return e.args[0]
    # okay so return None
    return None


@app.callback(Output('run-info', 'children'), [Input('run-id', 'data')])
def update_run_info(run_id):
    if run_id is None:
        return None
    else:
        return html.Div([
            html.H3(f"Run {run_id} at path {run_path(run_id)}")
        ])

#####


@app.callback(Output('network-graph', 'figure'),
              [Input('run-id', 'data'), Input('network-graph-slider', 'value')])
def update_network_graph(run_id, t):
    logging.info(f'Updating network-graph for run_id: {run_id}, t: {t}')
    if run_id is None:
        return None
    changed_places = changed_places_df(run_id)
    changed_places.dropna(inplace=True)
    figure = pyspike.network_dash.generate_network_figure(
        changed_places, medium_graph(run_id), sacred_run(run_id), t)
    return figure


@app.callback(Output('network-graph-slider-keeper', 'children'),
              [Input('run-id', 'data')])
def def_update_network_graph_slider(run_id):
    if run_id is None:
        return None
    logging.info(f'network-graph-slider-keeper for run_id: {run_id}')
    unique_times = changed_places_df(run_id)['time'].unique()
    dct = {t: '' for t in unique_times}
    # label the first and last only (or they overlap)
    dct[unique_times[0]] = str(unique_times[0])
    dct[unique_times[-1]] = str(unique_times[-1])

    return dcc.Slider(
        id='network-graph-slider',
        min=unique_times[0],
        max=unique_times[-1],
        step=None,
        marks=dct,
        value=unique_times[0],
        updatemode='drag',
    )


@app.callback(Output('place-count-graph', 'figure'), [Input('run-id', 'data')])
def update_place_count_graph(run_id):
    logging.info(f'Updating place-count-graph for run_id: {run_id}')
    if run_id is None:
        return None
    return occ.vis.analysis.generate_sums_by_state_figure(places=places_df(run_id))



# @app.callback(Output('occasion-graph-graph', 'figure'),
#               [Input('run-id', 'data')])
# def update_occasion_graph_graph(run_id):
#     if run_id is None:
#         return None
#
#     run = sacred_run(run_id)
#     tstep = run.config['spike']['sim_args']['interval']['step']
#     changed_places = changed_places_df(run_id)
#
#     # non coloured sums must be dropped before filtering out on change events
#     # (so cannot use the existing changed_places_df() function)
#     # TODO: if this fixes it then move out into a memoizable functin
#     # TODO: update it turns out that this is not
#     places = places_df(run_id)
#     changed_places.dropna(inplace=True)
#     place_changes = temporal.filter_place_changed_events(places)
#     place_changes.sort_values('tstep')
#
#     transitions = tidydata.read_csv(filename=str(run.transitions_path), node_type="transition", drop_non_coloured_sums=True)
#     transitions = pyspike.tidydata.prepend_tidy_frame_with_tstep(transitions)
#     transition_events = pyspike.temporal.generate_transition_events(transitions)
#
#     occasion_graph = pyspike.temporal.generate_causal_graph(
#         changed_places, transition_events, time_per_step=tstep)
#
#     return pyspike.temporal.generate_causal_graph_figure(
#         occasion_graph, medium_graph(run_id))

########


@app.callback(Output('occasion-graph-graph', 'figure'),
              [Input('run-id', 'data')])
def update_occasion_graph_graph(run_id):
    if run_id is None:
        return None

    run = sacred_run(run_id)
    tstep = run.config['spike']['sim_args']['interval']['step']

    places = tidydata.read_csv(filename=str(run.places_path), node_type="place", drop_non_coloured_sums=True)
    transitions = tidydata.read_csv(filename=str(run.transitions_path), node_type="transition", drop_non_coloured_sums=True)
    _, _, tstep = tidydata.determine_time_range_of_data_frame(places)
    places = pyspike.tidydata.prepend_tidy_frame_with_tstep(places)
    transitions = pyspike.tidydata.prepend_tidy_frame_with_tstep(transitions)

    place_change_events = pyspike.temporal.generate_place_increased_events(places)
    transition_events = pyspike.temporal.generate_transition_events(transitions)

    occasion_graph = pyspike.temporal.generate_causal_graph(
        place_change_events, transition_events, time_per_step=tstep)

    return pyspike.temporal.generate_causal_graph_figure(
            occasion_graph, medium_graph(run_id))
    return causal_graph

#########


# @app.callback(
#     Output('occasion-graph-graph', 'figure'),
#     [Input('place-count-graph', 'relayoutData')],
#     [State('occasion-graph-graph', 'figure')])
def update_causal_graph_range(relayout_data, occ_graph):
    if relayout_data and ('xaxis.range' in relayout_data):
        t_min, t_max = relayout_data['xaxis.range']
    elif relayout_data and ('xaxis.range[0]' in relayout_data):
        t_min = relayout_data['xaxis.range[0]']
        t_max = relayout_data['xaxis.range[1]']
    else:
        return occ_graph

    occ_graph['layout']['scene']['zaxis']['autorange'] = False
    occ_graph['layout']['scene']['zaxis']['range'] = (t_min, t_max)
    return occ_graph
    # return json.dumps(relayout_data, indent=2)


#####

def run_id_from_url(pathname):
    if not pathname:
        raise ValueError("url path must begin with '/run-'. It is ''")
    elif not pathname.startswith('/run-'):
        raise ValueError(f"url path must begin with '/run-'. It is '{pathname}'")
    else:
        _, num = pathname.split('/run-')
        run_path = RUN_PATH_BASE / str(num)
        if (not run_path.exists()) or (not run_path.is_dir()):
            raise ValueError("run number {} does not point to a run directory. '{}' is not a directory".format(num, run_path))
    return num


def graph_to_json(g: nx.Graph):
    data = networkx.readwrite.json_graph.node_link_data(g)
    return json.dumps(data)


def json_to_graph(s: str):
    data = json.loads(s)
    return networkx.readwrite.json_graph.node_link_graph(data)


###

@cache.memoize()
def places_df(run_id):
    run = sacred_run(run_id)
    places = tidydata.read_csv(filename=str(run.places_path), node_type="place", drop_non_coloured_sums=False)
    places = pyspike.tidydata.prepend_tidy_frame_with_tstep(places)
    return places
    # return places.to_json(orient='split')


@cache.memoize()
def changed_places_df(run_id):
    places = places_df(run_id)
    place_changes = temporal.filter_place_changed_events(places)
    place_changes.sort_values('tstep')
    return place_changes
    # return place_changes.to_json(orient='split')


@cache.memoize()
def medium_graph(run_id):
    run = sacred_run(run_id)
    return load_medium_graph(run.medium_graph_path)
    # return graph_to_json(g)

#####

def run_path(run_id):
    return RUN_PATH_BASE / str(run_id)


def sacred_run(run_id):
    return SacredRun(run_path(run_id))






if __name__ == '__main__':
    app.run_server(debug=True)
